{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a835ae32-2e14-49d9-85a1-12708cc13dea",
   "metadata": {},
   "source": [
    "# Goodness of fit estimation for GW events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5b345-a4b0-4b36-8a6c-2069e9ec20e6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73daea5a-d0b3-43dc-8254-8aa6169ea30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stan/Documents/python_envs/genova/lib/python3.12/site-packages/gwpy/time/__init__.py:36: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(False)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  from lal import LIGOTimeGPS\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "## General purpose ##\n",
    "#####################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# ###########\n",
    "# ## Bilby ##\n",
    "# ###########\n",
    "# import bilby\n",
    "# from bilby.gw.detector import InterferometerList\n",
    "# from bilby.gw.likelihood import GravitationalWaveTransient\n",
    "# from bilby.gw.waveform_generator import WaveformGenerator\n",
    "# from bilby.gw.source import lal_binary_black_hole\n",
    "# logger = bilby.core.utils.logger\n",
    "\n",
    "\n",
    "# ###########\n",
    "# ## GWOSC ##\n",
    "# ###########\n",
    "# from gwosc.datasets import event_gps\n",
    "# from gwosc.api import fetch_event_json\n",
    "# from gwosc.locate import get_event_urls\n",
    "# from gwosc import datasets\n",
    "\n",
    "\n",
    "#############\n",
    "## Getdist ##\n",
    "#############\n",
    "from getdist import MCSamples\n",
    "from getdist import plots\n",
    "\n",
    "\n",
    "###########\n",
    "## Other ##\n",
    "###########\n",
    "from gwpy.timeseries import TimeSeries\n",
    "from pesummary.gw.fetch import fetch_open_samples\n",
    "from pesummary.io import read\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "###########\n",
    "## Utils ##\n",
    "###########\n",
    "import utils as gwut\n",
    "from tensiometer.utilities import KL_decomposition, from_confidence_to_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ece79-3e68-46de-8c6a-20d8e8f930e5",
   "metadata": {},
   "source": [
    "### Model and parameters\n",
    "We assume a model parametrization with the following 15 parameters:\n",
    "\n",
    "| Parameter             | Periodic? | Periodic Range |\n",
    "| --------------------- | --------- | -------------- |\n",
    "| `chirp_mass`          | No        | –              |\n",
    "| `azimuth`             | No        | –              |\n",
    "| `zenith`              | No        | –              |\n",
    "| `phase`               | Yes       | \\[0, 2π]       |\n",
    "| `psi`                 | Yes       | \\[0, π]        |\n",
    "| `theta_jn`            | No        | –              |\n",
    "| `mass_ratio`          | No        | –              |\n",
    "| `a_1`                 | No        | –              |\n",
    "| `a_2`                 | No        | –              |\n",
    "| `tilt_1`              | No        | –              |\n",
    "| `tilt_2`              | No        | –              |\n",
    "| `phi_12`              | Yes       | \\[0, 2π]       |\n",
    "| `phi_jl`              | Yes       | \\[0, 2π]       |\n",
    "| `luminosity_distance` | No        | –              |\n",
    "| `geocent_time`        | No        | –              |\n",
    "\n",
    "#### Parameter names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5e5705-ef3c-40f5-a3df-b503ce6465d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMS = [\"chirp_mass\",\n",
    "                \"ra\",\n",
    "                \"dec\",\n",
    "                # \"azimuth\",   # Equivalent of ra in some param estimations\n",
    "                # \"zenith\",    # Equivalent of dec in some param estimations\n",
    "                \"phase\",\n",
    "                \"psi\",\n",
    "                \"theta_jn\",\n",
    "                \"mass_ratio\",\n",
    "                \"a_1\",\n",
    "                \"a_2\",\n",
    "                \"tilt_1\",\n",
    "                \"tilt_2\",\n",
    "                \"phi_12\",\n",
    "                \"phi_jl\",\n",
    "                \"luminosity_distance\",\n",
    "                \"geocent_time\",\n",
    "                ]\n",
    "\n",
    "# Periodicity of the params\n",
    "PERIOD_PARAM_DICT = {\"phi_12\": [0, 2*np.pi],\n",
    "                     \"phi_jl\": [0, 2*np.pi],\n",
    "                     \"phase\":[0, 2*np.pi],\n",
    "                     \"psi\": [0, np.pi],\n",
    "                     \"ra\": [0, 2*np.pi],\n",
    "                     # \"dec\": [-np.pi/2, np.pi/2],  # Should not be periodic???\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573a38f-fdca-4dac-bb71-cdeed0cdb5bd",
   "metadata": {},
   "source": [
    "#### Event under consideration\n",
    "We will define the model later, based on which prior samples are available\n",
    "\n",
    "We can put any event here, and the rest of the notebook will take care of (down)loading the data, and getting the different $Q$ estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d3b256-2ed7-4866-be10-e89afb65084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT = \"GW190521\"\n",
    "# EVENT = \"GW200129_065458\"\n",
    "# EVENT = \"GW190412\"\n",
    "# EVENT = \"GW151226\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e771a6d-6020-4ca0-963f-981f55e048b0",
   "metadata": {},
   "source": [
    "### Fetching event posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de9c452-4472-45ef-a493-84310c3c2976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Directory already exists. Now loading data...\n",
      "    GW190521/GW190521_posterior_samples.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17  00:07:21 PESummary WARNING : Unable to install 'pycbc'. You will not be able to use some of the inbuilt functions.\n",
      "2025-06-17  00:07:21 PESummary WARNING : Unable to install 'pycbc'. You will not be able to use some of the inbuilt functions.\n",
      "2025-06-17  00:07:23 PESummary WARNING : Could not find f_final in input file and one was not passed from the command line. Using 1024.0Hz as default\n",
      "2025-06-17  00:07:23 PESummary WARNING : Could not find delta_f in input file and one was not passed from the command line. Using 0.00390625Hz as default\n",
      "2025-06-17  00:07:23 PESummary WARNING : Could not find f_start in input file and one was not passed from the command line. Using 20.0Hz as default\n"
     ]
    }
   ],
   "source": [
    "# Check if file is already downloaded\n",
    "if os.path.exists(f\"{EVENT}\"):\n",
    "    print(\"INFO: Directory already exists. Now loading data...\")\n",
    "    path = Path(f\"{EVENT}\")\n",
    "    files = list(path.glob(\"*.h5\"))\n",
    "    file = [file for file in files if EVENT in file.name][0]\n",
    "    print(\"   \", file)\n",
    "    data = read(file)\n",
    "else:\n",
    "    print(\"INFO: Couldn't find data. Now downloading...\")\n",
    "    # Create directory to store event data in\n",
    "    os.mkdir(f\"{EVENT}\")\n",
    "\n",
    "    # Download data if it did not exist\n",
    "    data = fetch_open_samples(\n",
    "        EVENT,\n",
    "        read_file=True,\n",
    "        delete_on_exit=False,\n",
    "        outdir=f\"./{EVENT}\",\n",
    "        path=f\"{EVENT}.h5\"\n",
    "    )\n",
    "\n",
    "# Samples and prior information\n",
    "samples = data.samples_dict\n",
    "priors = data.priors\n",
    "\n",
    "calibration = priors[\"calibration\"]\n",
    "prior_samples = priors[\"samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a861781-df73-42f4-926a-5f193f8246aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'NRSur7dq4' has prior samples.\n"
     ]
    }
   ],
   "source": [
    "# Loop over models in the prior_samples dict and check for non-empty samples\n",
    "# Only takes the first non-empty model for now\n",
    "for model, prior in prior_samples.items():\n",
    "    if len(prior) > 0:\n",
    "        print(f\"Model '{model}' has prior samples.\")\n",
    "        MODEL = model\n",
    "        break\n",
    "else:\n",
    "    print(\"No prior samples found for any model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de725cf-b329-47de-a365-402230cd2c72",
   "metadata": {},
   "source": [
    "### MCSamples\n",
    "We convert the prior and posterior samples to MCSamples objects. For completeness, we also show all available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7958e63b-86d3-419a-ae60-8e9773416561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All available models:\n",
      "    IMRPhenomPv3HM\n",
      "    NRSur7dq4 <--- Currenty using\n",
      "    SEOBNRv4PHM\n",
      "Removed 0.3 as burn in\n",
      "Removed 0.3 as burn in\n"
     ]
    }
   ],
   "source": [
    "available_models = samples.keys()\n",
    "print(\"All available models:\")\n",
    "for m in available_models:\n",
    "    if m == MODEL:\n",
    "        print(\"   \", m, \"<--- Currenty using\")\n",
    "        continue\n",
    "    print(\"   \", m)\n",
    "\n",
    "getdist_settings = {\n",
    "    'smooth_scale_1D': 0.3,\n",
    "    'smooth_scale_2D': 0.4,\n",
    "    'boundary_correction_order': 1,\n",
    "    'mult_bias_correction_order': 1,\n",
    "    'ignore_rows': 0.3\n",
    "    }\n",
    "\n",
    "\n",
    "# Create MCSamples objects for posterior and prior\n",
    "mcs_posterior = MCSamples(samples = samples[MODEL].samples.T, names = samples[MODEL].keys(), label=\"Posterior\", settings=getdist_settings)\n",
    "mcs_prior = MCSamples(samples = prior_samples[MODEL].samples.T, names = prior_samples[MODEL].keys(), label=\"Prior\", settings=getdist_settings)\n",
    "\n",
    "# mcs_posterior.updateSettings(getdist_settings)\n",
    "# mcs_posterior.updateBaseStatistics()\n",
    "\n",
    "# mcs_prior.updateSettings(getdist_settings)\n",
    "# mcs_prior.updateBaseStatistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac7b47-0efa-4910-9b16-b9ad2abdd502",
   "metadata": {},
   "source": [
    "### GoF preparation\n",
    "To determine a GoF, we need the effective number of freedoms, as well as the prior and posterior covariances $\\mathcal{C}_p$ and $\\mathcal{C}_\\Pi$. For this, we need to take into account the periodicity of some of the parameters, which we achieve using a utilities script from Giulia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a95638-06fd-4f57-9912-6a2aa4b3dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effective number of freedoms\n",
    "Neff = gwut.get_Neff_with_periodic_boundaries(mcs_posterior, mcs_prior, MODEL_PARAMS, PERIOD_PARAM_DICT)\n",
    "\n",
    "# Covariance matrices\n",
    "Cpi = gwut.covariance_with_periodic_params(mcs_prior, MODEL_PARAMS, PERIOD_PARAM_DICT)\n",
    "Cp = gwut.covariance_with_periodic_params(mcs_posterior, MODEL_PARAMS, PERIOD_PARAM_DICT)\n",
    "\n",
    "# Inverses\n",
    "Cpi_inv = np.linalg.inv(Cpi)\n",
    "Cp_inv = np.linalg.inv(Cp)\n",
    "\n",
    "# Data covariance matrix\n",
    "C_inv = Cp_inv - Cpi_inv\n",
    "C = np.linalg.inv(C_inv)\n",
    "\n",
    "# Get means\n",
    "mu_posterior = gwut.circular_mean_ND(mcs_posterior, MODEL_PARAMS, PERIOD_PARAM_DICT)\n",
    "mu_prior = gwut.circular_mean_ND(mcs_prior, MODEL_PARAMS, PERIOD_PARAM_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3824d96-b792-4dfb-b06b-e51d10aadb67",
   "metadata": {},
   "source": [
    "### Quadratic forms\n",
    "#### Prior compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ee7f1e-0e71-43e5-8b8d-e2821b1bb878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effecve sigma: 2.6297686705620396\n"
     ]
    }
   ],
   "source": [
    "# Difference between prior and posterior means\n",
    "delta_theta_pi = mu_posterior - mu_prior\n",
    "\n",
    "# Decompose using KL\n",
    "eig, phi = KL_decomposition(Cpi, Cp)\n",
    "\n",
    "# Need to use phi.T for some reason?\n",
    "# We don't know why??\n",
    "delta_p = phi.T @ delta_theta_pi\n",
    "\n",
    "# Throw away everything below 1.2\n",
    "MASK = eig > 1.2\n",
    "number_thrown_away = np.sum(~MASK)\n",
    "\n",
    "# Calculate the quadratic form\n",
    "Q_pi = np.sum(delta_p[MASK]**2 / (eig[MASK] - 1))\n",
    "\n",
    "p_value = 1 - chi2.cdf(Q_pi, df=len(MODEL_PARAMS) - number_thrown_away)\n",
    "\n",
    "print(\"Effecve sigma:\", from_confidence_to_sigma(1-p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43952e0-d7c6-47f2-b1a6-f9f3ce47f07e",
   "metadata": {},
   "source": [
    "#### Maximum a Posteriori \n",
    "Need to calulate $Q_\\mathrm{MAP}$:\n",
    "* $\\theta_p$\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f739c27-5942-4a23-882a-f599ce9100f1",
   "metadata": {},
   "source": [
    "#### Maximum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d67432e-7d99-4a30-9461-b9291cd25778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1280465.3197104363\n",
      "(12288,)\n",
      "11903.911397937623\n",
      "0.9912393700455204\n",
      "Effecve sigma: 0.010980041997812716\n"
     ]
    }
   ],
   "source": [
    "PSD = []\n",
    "\n",
    "for det in calibration[MODEL].detectors:\n",
    "    strain = data.psd[MODEL][det].strains\n",
    "    PSD.append(strain)\n",
    "\n",
    "PSD = np.concatenate(PSD)\n",
    "Sigma = np.diag(PSD)\n",
    "Sigma_det = np.prod(PSD)\n",
    "\n",
    "print(np.sum(np.log(PSD)))\n",
    "print(PSD.shape)\n",
    "\n",
    "\n",
    "# TODO: normalization constants (d * ln(2pi) - ln|Sigma|), check if correct???\n",
    "# Factor -2 is now -1??? Is log_likelihood actually chi2 / 2??\n",
    "# Need to check further...\n",
    "Q_ML =  -1 * samples[MODEL][\"log_likelihood\"].max() # - np.sum(np.log(PSD)) - len(PSD) * np.log(2*np.pi)\n",
    "print(Q_ML)\n",
    "p_value = 1 - chi2.cdf(Q_ML, df=len(PSD) - len(MODEL_PARAMS))\n",
    "print(p_value)\n",
    "\n",
    "print(\"Effecve sigma:\", from_confidence_to_sigma(1-p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0988c-c346-4591-b48e-78c0cd271d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
